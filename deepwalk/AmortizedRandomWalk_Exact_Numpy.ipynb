{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import math \n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import array as arr\n",
    "import copy\n",
    "\n",
    "filepathTXT = \"../edgelists/BlogCatalog-edgelist.txt\"\n",
    "filepathCSV = \"../edgelists/BlogCatalog-edgelist.csv\"\n",
    "embeddingsrecursive = \"../embeddings/BlogCatalog-edgelist.txt.embeddings-recursive\"\n",
    "embeddingsiterative = \"../embeddings/BlogCatalog-edgelist.txt.embeddings-iterative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseEdgeList2(graph_file, direction=\"undirected\"):\n",
    "    # Create Graph\n",
    "    G = nx.Graph()\n",
    "    # Create head\n",
    "    colNames=[\"Start\", \"End\"]\n",
    "    edgeData = pd.read_csv(filepathCSV, names=colNames)\n",
    "\n",
    "    #Add nodes\n",
    "    nodes = []\n",
    "    #loop throug data records\n",
    "    for i in range (0, edgeData.shape[0]):\n",
    "        #append every node\n",
    "        nodes.append(edgeData.iloc[i,0])\n",
    "        nodes.append(edgeData.iloc[i,1])\n",
    "    #creating a set of nodes    \n",
    "    nodes = set(nodes)\n",
    "    #sorting the nodes in increasing order\n",
    "    uniqueNodes = (list(nodes))\n",
    "    uniqueNodes.sort()\n",
    "    #adding the nodes to the graph\n",
    "    G.add_nodes_from(uniqueNodes)\n",
    "\n",
    "    # Add edges\n",
    "    #loop from 0 to amount of records\n",
    "    edgeCount = 0\n",
    "    for i in range (0, edgeData.shape[0]):\n",
    "        edgeCount += 1\n",
    "        #add the edge to the graph\n",
    "        G.add_edge(edgeData.iloc[i,0], edgeData.iloc[i,1])\n",
    "    print(\"Nodes: \", G.number_of_nodes(),\" Edges: \", G.number_of_edges(), \" loaded from \", graph_file)\n",
    "\n",
    "    if(direction == \"undirected\"):\n",
    "        return G.to_undirected()\n",
    "    else:\n",
    "        return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAdjNPList(graph):\n",
    "    adjdict = {}\n",
    "    for vertex in graph:\n",
    "        adjdict[vertex] = np.array([n for n in G.neighbors(vertex)]) \n",
    "        np.random.shuffle(adjdict[vertex])\n",
    "    return adjdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "femb_recursive = open(embeddingsrecursive, 'w')\n",
    "femb_iterative = open(embeddingsiterative, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toyGraph():\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from([1,2,3,4,5,6,7,8,9,10,11])\n",
    "    G.add_edge(2, 1);G.add_edge(3, 1);G.add_edge(3, 2);G.add_edge(4, 1);\n",
    "    G.add_edge(4, 2);G.add_edge(4, 3);G.add_edge(5, 1);G.add_edge(6, 1);\n",
    "    G.add_edge(7, 1);G.add_edge(7, 5);G.add_edge(7, 6);G.add_edge(8, 1);\n",
    "    G.add_edge(8, 2);G.add_edge(8, 3);G.add_edge(8, 4);G.add_edge(9, 1); \n",
    "    G.add_edge(9, 3);G.add_edge(10, 3);G.add_edge(11, 1);G.add_edge(11, 5);\n",
    "    print(\"Nodes: \", G.number_of_nodes(),\" Edges: \", G.number_of_edges())\n",
    "    # Draw graph\n",
    "    # nx.draw(G, with_labels = True)\n",
    "    # plt.show()\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NP implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseNodes(list_nodes, sample_size):\n",
    "    return random.sample(population=list_nodes, k=sample_size) # 2.22 s Â± 179 ms per loop  (labesl str)\n",
    "\n",
    "def getPerNodeBudget(numNodes, budget):\n",
    "    return math.floor(budget/numNodes)\n",
    "\n",
    "def storeContextPairs(context_pair, budget, context_pairs):\n",
    "    if context_pair not in context_pairs:\n",
    "        context_pairs[context_pair] = budget\n",
    "    else:\n",
    "        context_pairs[context_pair] = context_pairs[context_pair] +  budget\n",
    "        \n",
    "def updateContextPairs(window, window_count, context_pairs):\n",
    "    lastNode = window[window_count]\n",
    "   \n",
    "    labelOfLastNode, budgetOfLastNode = lastNode\n",
    "    if window_count > ORIGINAL_WINDOW_SIZE:\n",
    "        new_window = window[ORIGINAL_WINDOW_SIZE:window_count]\n",
    "    else:\n",
    "        new_window = window[:window_count]\n",
    "\n",
    "    for node in new_window:\n",
    "        node_label = node[0]\n",
    "        context_pair1 = str(labelOfLastNode) +\",\"+ str(node_label)\n",
    "        context_pair2 = str(node_label) + \",\" + str(labelOfLastNode)\n",
    "        storeContextPairs(context_pair1, budgetOfLastNode, context_pairs)\n",
    "        storeContextPairs(context_pair2, budgetOfLastNode, context_pairs)\n",
    "           \n",
    "def addNewNodeToWindow(tempwindow, temp_window_count, window_size, vertex, budget):\n",
    "    if temp_window_count == window_size:\n",
    "        tempwindow = tempwindow[1:]\n",
    "        \n",
    "    newWindowElement = np.array([[vertex,budget]])\n",
    "    tempwindow[temp_window_count+1] = newWindowElement\n",
    "    temp_window_count+=1\n",
    "    return tempwindow, temp_window_count\n",
    "\n",
    "def BFSRandomWalkWindow(queue, queue_count, context_pairs, window_size, walk_lenght):\n",
    "   \n",
    "    while queue_count > -1:\n",
    "        vertex, budget, current_walk_lenght, window, window_count = queue[queue_count]\n",
    "        queue_count -= 1\n",
    "        queue = queue[1:]\n",
    "        vertex_neighbors = adjdict[vertex]\n",
    "        num_neighbors = vertex_neighbors.size\n",
    "        m = getPerNodeBudget(num_neighbors, budget)\n",
    "        remainder = budget - (m * num_neighbors)\n",
    "\n",
    "        if remainder > 0:\n",
    "            np.random.shuffle(vertex_neighbors) \n",
    "        else:\n",
    "            remainder = num_neighbors \n",
    "        current_walk_lenght += 1\n",
    "        \n",
    "        for neighbor in vertex_neighbors[:remainder]:\n",
    "            budget_for_this_node = m \n",
    "            temp_window = np.copy(window)\n",
    "            temp_window_count = window_count\n",
    "            \n",
    "            if remainder != num_neighbors:\n",
    "                budget_for_this_node = budget_for_this_node + 1\n",
    "            temp_window, temp_window_count = addNewNodeToWindow(temp_window, temp_window_count, window_size, neighbor, budget_for_this_node) \n",
    "            updateContextPairs(temp_window, temp_window_count, context_pairs) \n",
    "            if current_walk_lenght < walk_lenght:\n",
    "                newQueueElement = np.array([[neighbor, budget_for_this_node, current_walk_lenght, temp_window, temp_window_count]])\n",
    "                queue[queue_count+1] = newQueueElement\n",
    "                queue_count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:  10312  Edges:  333983  loaded from  ../edgelists/BlogCatalog-edgelist.csv\n"
     ]
    }
   ],
   "source": [
    "# Set the actual parameters and graph\n",
    "WALK_LENGHT = 40\n",
    "BUDGET = 80\n",
    "ORIGINAL_WINDOW_SIZE = 10\n",
    "G = parseEdgeList2(filepathCSV) # Integer labels\n",
    "adjdict = getAdjNPList(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set toy parameters and graph\n",
    "WALK_LENGHT = 3\n",
    "BUDGET = 1\n",
    "ORIGINAL_WINDOW_SIZE = 1\n",
    "G = toyGraph()\n",
    "adjdict = getAdjNPList(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NP Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Runner():\n",
    "    start = time.time()\n",
    "    random.seed(0)\n",
    "    rand=random.Random(0)\n",
    "    \n",
    "    context_pairs = {}    \n",
    "    WINDOW_SIZE = ORIGINAL_WINDOW_SIZE*2+1\n",
    "    \n",
    "    print(\"Running BFSRandomWalkWindow...\")\n",
    "    count = 0\n",
    "    for startvertex in adjdict.keys():\n",
    "        count+=1\n",
    "        if count == 10000:\n",
    "            end = time.time()\n",
    "            result = end - start\n",
    "            print(\"10000 iterations in ->\", result)\n",
    "            break\n",
    "\n",
    "        #print(\"Running from -> \", startvertex)\n",
    "        \n",
    "        window_count = 0\n",
    "        WINDOW = np.zeros(shape=(WINDOW_SIZE+20,2),dtype=int)\n",
    "        firstWindowElement = np.array([[startvertex, BUDGET]])\n",
    "        WINDOW[window_count] = firstWindowElement\n",
    " \n",
    "        queue_count = 0\n",
    "        queue = np.zeros(shape=(BUDGET+100,5),dtype=object)\n",
    "        firstQueueElement = np.array([[startvertex, BUDGET, 1, WINDOW, window_count]])\n",
    "        queue[queue_count] = firstQueueElement\n",
    "\n",
    "        BFSRandomWalkWindow(queue, queue_count, context_pairs, WINDOW_SIZE, WALK_LENGHT)\n",
    "    return context_pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BFSRandomWalkWindow...\n",
      "10000 iterations in -> 115.18561029434204\n"
     ]
    }
   ],
   "source": [
    "contextPairs = Runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total value sums up to:  29138736\n"
     ]
    }
   ],
   "source": [
    "# Count the total count sum\n",
    "countSum = 0\n",
    "for key, value in contextPairs.items():\n",
    "    countSum += value\n",
    "print(\"Total value sums up to: \", countSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing context pairs to file...\")    \n",
    "#Writing to file    \n",
    "for (key, value) in contextPairs.items():\n",
    "    \n",
    "    femb_iterative.write(str(key) + \" \" + str(value) + \"\\n\" )\n",
    "femb_iterative.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
