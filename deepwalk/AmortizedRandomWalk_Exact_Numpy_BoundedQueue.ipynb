{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import math \n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import array as arr\n",
    "import copy\n",
    "\n",
    "filepathTXT = \"../edgelists/BlogCatalog-edgelist.txt\"\n",
    "filepathCSV = \"../edgelists/BlogCatalog-edgelist.csv\"\n",
    "embeddingsrecursive = \"../embeddings/BlogCatalog-edgelist.txt.embeddings-recursive\"\n",
    "embeddingsiterative = \"../embeddings/BlogCatalog-edgelist.txt.embeddings-iterative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseEdgeList2(graph_file, direction=\"undirected\"):\n",
    "    # Create Graph\n",
    "    G = nx.Graph()\n",
    "    # Create head\n",
    "    colNames=[\"Start\", \"End\"]\n",
    "    edgeData = pd.read_csv(filepathCSV, names=colNames)\n",
    "\n",
    "    #Add nodes\n",
    "    nodes = []\n",
    "    #loop throug data records\n",
    "    for i in range (0, edgeData.shape[0]):\n",
    "        #append every node\n",
    "        nodes.append(edgeData.iloc[i,0])\n",
    "        nodes.append(edgeData.iloc[i,1])\n",
    "    #creating a set of nodes    \n",
    "    nodes = set(nodes)\n",
    "    #sorting the nodes in increasing order\n",
    "    uniqueNodes = (list(nodes))\n",
    "    uniqueNodes.sort()\n",
    "    #adding the nodes to the graph\n",
    "    G.add_nodes_from(uniqueNodes)\n",
    "\n",
    "    # Add edges\n",
    "    #loop from 0 to amount of records\n",
    "    edgeCount = 0\n",
    "    for i in range (0, edgeData.shape[0]):\n",
    "        edgeCount += 1\n",
    "        #add the edge to the graph\n",
    "        G.add_edge(edgeData.iloc[i,0], edgeData.iloc[i,1])\n",
    "    print(\"Nodes: \", G.number_of_nodes(),\" Edges: \", G.number_of_edges(), \" loaded from \", graph_file)\n",
    "\n",
    "    if(direction == \"undirected\"):\n",
    "        return G.to_undirected()\n",
    "    else:\n",
    "        return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAdjNPList(graph):\n",
    "    adjdict = {}\n",
    "    for vertex in graph:\n",
    "        adjdict[vertex] = np.array([n for n in G.neighbors(vertex)]) \n",
    "        np.random.shuffle(adjdict[vertex])\n",
    "    return adjdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "femb_recursive = open(embeddingsrecursive, 'w')\n",
    "femb_iterative = open(embeddingsiterative, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toyGraph():\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from([1,2,3,4,5,6,7,8,9,10,11])\n",
    "    G.add_edge(2, 1);G.add_edge(3, 1);G.add_edge(3, 2);G.add_edge(4, 1);\n",
    "    G.add_edge(4, 2);G.add_edge(4, 3);G.add_edge(5, 1);G.add_edge(6, 1);\n",
    "    G.add_edge(7, 1);G.add_edge(7, 5);G.add_edge(7, 6);G.add_edge(8, 1);\n",
    "    G.add_edge(8, 2);G.add_edge(8, 3);G.add_edge(8, 4);G.add_edge(9, 1); \n",
    "    G.add_edge(9, 3);G.add_edge(10, 3);G.add_edge(11, 1);G.add_edge(11, 5);\n",
    "    print(\"Nodes: \", G.number_of_nodes(),\" Edges: \", G.number_of_edges())\n",
    "    # Draw graph\n",
    "    # nx.draw(G, with_labels = True)\n",
    "    # plt.show()\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NP implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseNodes(list_nodes, sample_size):\n",
    "    return random.sample(population=list_nodes, k=sample_size) # 2.22 s Â± 179 ms per loop  (labesl str)\n",
    "\n",
    "def getPerNodeBudget(numNodes, budget):\n",
    "    return math.floor(budget/numNodes)\n",
    "\n",
    "def storeContextPairs(context_pair, budget, context_pairs):\n",
    "    if context_pair not in context_pairs:\n",
    "        context_pairs[context_pair] = budget\n",
    "    else:\n",
    "        context_pairs[context_pair] = context_pairs[context_pair] +  budget\n",
    "        \n",
    "def updateContextPairs(window, window_count, context_pairs):\n",
    "    lastNode = window[window_count]\n",
    "    labelOfLastNode, budgetOfLastNode = lastNode\n",
    "    index_count = 0\n",
    "    window_except_last = window[:window_count]\n",
    "    window_reversed = window_except_last[::-1]\n",
    "    for node in window_reversed:\n",
    "        node_label = node[0]\n",
    "        if index_count == ORIGINAL_WINDOW_SIZE:\n",
    "            break\n",
    "        context_pair1 = str(labelOfLastNode) +\",\"+ str(node_label)\n",
    "        context_pair2 = str(node_label) + \",\" + str(labelOfLastNode)\n",
    "        storeContextPairs(context_pair1, budgetOfLastNode, context_pairs)\n",
    "        storeContextPairs(context_pair2, budgetOfLastNode, context_pairs)\n",
    "        index_count = index_count + 1\n",
    "\n",
    "def addNewNodeToWindow(tempwindow, temp_window_count, window_size, vertex, budget):\n",
    "    newWindowElement = np.array([[vertex,budget]])\n",
    "    if temp_window_count+1 == window_size:\n",
    "        tempwindow = tempwindow[1:]\n",
    "        tempwindow[temp_window_count] = newWindowElement\n",
    "        return tempwindow, temp_window_count\n",
    "\n",
    "    tempwindow[temp_window_count+1] = newWindowElement\n",
    "    temp_window_count+=1\n",
    "    return tempwindow, temp_window_count\n",
    "\n",
    "def BFSRandomWalkWindow(queue, queue_len, queue_pop_idx, queue_add_idx, context_pairs, window_size, walk_lenght):\n",
    "    queue_buffer_size = (queue.size/5)-1\n",
    "    while queue_len > 0:\n",
    "        vertex, budget, current_walk_lenght, window_count, window = queue[queue_pop_idx] \n",
    "        queue_len -=1\n",
    "        if queue_len > 0:\n",
    "            if queue_pop_idx == queue_buffer_size:\n",
    "                queue_pop_idx = 0\n",
    "            else:\n",
    "                queue_pop_idx += 1\n",
    "        vertex_neighbors = adjdict[vertex]\n",
    "        num_neighbors = vertex_neighbors.size\n",
    "        m = getPerNodeBudget(num_neighbors, budget)\n",
    "        remainder = budget - (m * num_neighbors)\n",
    "        if remainder > 0:\n",
    "            np.random.shuffle(vertex_neighbors) \n",
    "        else:\n",
    "            remainder = num_neighbors \n",
    "        current_walk_lenght += 1\n",
    "        for neighbor in vertex_neighbors[:remainder]:\n",
    "            budget_for_this_node = m \n",
    "            temp_window = np.copy(window)\n",
    "            temp_window_count = window_count\n",
    "            if remainder != num_neighbors:\n",
    "                budget_for_this_node = budget_for_this_node + 1\n",
    "            temp_window, temp_window_count = addNewNodeToWindow(temp_window, temp_window_count, window_size, neighbor, budget_for_this_node) \n",
    "            updateContextPairs(temp_window, temp_window_count, context_pairs) \n",
    "            if current_walk_lenght < walk_lenght:\n",
    "                newQueueElement = np.array([[neighbor, budget_for_this_node, current_walk_lenght, temp_window_count, temp_window]])\n",
    "                queue[queue_add_idx] = newQueueElement\n",
    "                if queue_add_idx == queue_buffer_size:\n",
    "                    queue_add_idx = 0\n",
    "                else:\n",
    "                    queue_add_idx += 1\n",
    "                queue_len+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set toy parameters and graph\n",
    "WALK_LENGHT = 3\n",
    "BUDGET = 1\n",
    "ORIGINAL_WINDOW_SIZE = 1\n",
    "WINDOW_SIZE = ORIGINAL_WINDOW_SIZE*2+1\n",
    "QUEUE_BUFFER_SIZE = (BUDGET*WALK_LENGHT)-(BUDGET*2) + 1\n",
    "\n",
    "G = toyGraph()\n",
    "adjdict = getAdjNPList(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:  10312  Edges:  333983  loaded from  ../edgelists/BlogCatalog-edgelist.csv\n"
     ]
    }
   ],
   "source": [
    "# Set the actual parameters and graph\n",
    "WALK_LENGHT = 40\n",
    "#BUDGET = 80\n",
    "BUDGET = 1\n",
    "ORIGINAL_WINDOW_SIZE = 10\n",
    "WINDOW_SIZE = ORIGINAL_WINDOW_SIZE*2+1\n",
    "QUEUE_BUFFER_SIZE = (BUDGET*WALK_LENGHT)-(BUDGET*2) + 1\n",
    "#G = parseEdgeList1(filepathTXT) #String labels \n",
    "\n",
    "G = parseEdgeList2(filepathCSV) # Integer labels\n",
    "adjdict = getAdjNPList(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NP Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Runner():\n",
    "\n",
    "    random.seed(0)\n",
    "    rand=random.Random(0)\n",
    "    context_pairs = {}    \n",
    "    print(\"Running BFSRandomWalkWindow...\")\n",
    "\n",
    "    for startvertex in adjdict.keys():\n",
    "        window_count = 0\n",
    "        WINDOW = np.zeros(shape=(WINDOW_SIZE+20,2),dtype=int)\n",
    "        firstWindowElement = np.array([[startvertex, BUDGET]])\n",
    "        WINDOW[window_count] = firstWindowElement\n",
    "        \n",
    "        queue_len = 0\n",
    "        queue_pop_idx = 0\n",
    "        queue_add_idx = 0\n",
    "        queue = np.zeros(shape=(BUDGET,5),dtype=object)\n",
    "        firstQueueElement = np.array([[startvertex, BUDGET, 1, window_count, WINDOW]])\n",
    "        queue[queue_len] = firstQueueElement\n",
    "        queue_len+=1\n",
    " \n",
    "        BFSRandomWalkWindow(queue, queue_len, queue_pop_idx, queue_add_idx, context_pairs, WINDOW_SIZE, WALK_LENGHT)\n",
    "    return context_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BFSRandomWalkWindow...\n"
     ]
    }
   ],
   "source": [
    "contextPairs = Runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total value sums up to:  7115280\n"
     ]
    }
   ],
   "source": [
    "# Count the total count sum\n",
    "countSum = 0\n",
    "for key, value in contextPairs.items():\n",
    "    countSum += value\n",
    "print(\"Total value sums up to: \", countSum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextPairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Writing context pairs to file...\")    \n",
    "#Writing to file    \n",
    "for (key, value) in contextPairs.items():\n",
    "    \n",
    "    femb_iterative.write(str(key) + \" \" + str(value) + \"\\n\" )\n",
    "femb_iterative.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
