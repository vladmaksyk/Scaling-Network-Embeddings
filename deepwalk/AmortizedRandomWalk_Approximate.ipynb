{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import math \n",
    "import time\n",
    "from random import shuffle\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T']"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vose_sampler import VoseAlias\n",
    "dist = {\"H\":0.2, \"T\":0.8}\n",
    "VA = VoseAlias(dist)\n",
    "VA.sample_n(size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = \"../edgelists/BlogCatalog-edgelist.txt\"\n",
    "filepath = \"../edgelists/karate-small.txt\"\n",
    "\n",
    "embeddingsiterative = filepath+\"-pairs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseEdgeList(graph_file, delimiter=\" \", weighted=False, direction=\"undirected\"):\n",
    "    if(weighted == False):\n",
    "        G = nx.read_edgelist(graph_file, delimiter=delimiter, nodetype=int)\n",
    "    else:\n",
    "        G = nx.read_edgelist(graph_file, delimiter=delimiter, nodetype=int, data=(('weight',float),))\n",
    "    print(G.number_of_nodes(), G.number_of_edges(), \" loaded from \", graph_file)\n",
    "    if(direction == \"undirected\"):\n",
    "        return G.to_undirected()\n",
    "    else:\n",
    "        return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = parseEdgeList(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "femb_recursive = open(embeddingsrecursive, 'w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createToyGraph():\n",
    "    G = nx.Graph()\n",
    "    #Small example\n",
    "    G.add_nodes_from([\"A\",\"D\",\"E\",\"J\",\"K\",\"L\",\"M\",\n",
    "                      \"V\",\"W\",\"X\",\"Y\",\"Z\",\"A1\",\"B1\",\"OX\",\"DX\"])\n",
    "    G.add_edge(\"A\", \"D\");G.add_edge(\"A\", \"E\");\n",
    "    G.add_edge(\"D\", \"J\");G.add_edge(\"D\", \"K\");\n",
    "    G.add_edge(\"E\", \"L\");G.add_edge(\"E\", \"M\");\n",
    "    G.add_edge(\"J\", \"V\");G.add_edge(\"J\", \"W\");\n",
    "    G.add_edge(\"K\", \"X\");\n",
    "    G.add_edge(\"L\", \"Y\");G.add_edge(\"L\", \"Z\");\n",
    "    G.add_edge(\"M\", \"A1\");G.add_edge(\"M\", \"B1\");\n",
    "    G.add_edge(\"V\", \"OX\");G.add_edge(\"V\", \"DX\");\n",
    "\n",
    "    # Draw graph\n",
    "    #nx.draw(G, with_labels = True)\n",
    "    #plt.show()\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walk with window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(arr, n_iter=None, sample_size=10, fast=True):\n",
    "    if fast:\n",
    "        # find the index we last sampled from\n",
    "        start_idx = (n_iter * sample_size) % n\n",
    "        if start_idx + sample_size >= n:\n",
    "            # shuffle array if we have reached the end and repeat again\n",
    "            np.random.shuffle(arr)\n",
    "        return arr[start_idx:start_idx+sample_size] \n",
    "    else:\n",
    "        return np.random.choice(arr, sample_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_samples(arr, sample_size, n_samples, fast=False):\n",
    "    samples = np.zeros((n_samples + 1, sample_size), np.int32)\n",
    "    #print(\"samples ->\", samples)\n",
    "    \n",
    "    for sample_n in range(0, n_samples):\n",
    "        sample = get_sample(arr, n_iter=sample_n, sample_size=sample_size, fast=fast)\n",
    "        samples[sample_n] = sample   \n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1\n",
    "sample_size = 5\n",
    "n_iter = 1\n",
    "arr = np.array([1,2,3,4,5,6,7,8,9,0]).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 6, 5, 0, 9])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sample(arr, n_iter, sample_size, fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 2, 1, 6], dtype=int32)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collect_samples(arr, sample_size, 1, fast=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodeContextSets(graph):\n",
    "    node_context = {}\n",
    "    for node in graph:\n",
    "        node_context[node] = (set(), 0)\n",
    "    return node_context\n",
    "node_context = getNodeContextSets(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseNodes(list_nodes, sample_size):\n",
    "    #n_iter = 1\n",
    "    #return np.random.choice(list_nodes, n, replace=False)\n",
    "    #return random.sample(population=list(list_nodes), k=sample_size)\n",
    "    return collect_samples(list_nodes, sample_size, 1, fast=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPerNodeBudget(numNodes, budget):\n",
    "    return math.floor(budget/numNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeContextPairs(context_pair, budget, context_pairs):\n",
    "    if context_pair not in context_pairs:\n",
    "        context_pairs[context_pair] = budget\n",
    "    else:\n",
    "        context_pairs[context_pair] = context_pairs[context_pair] +  budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateSetCount(node, context_node, context_budget):\n",
    "    context_set = node_context[node][0]\n",
    "    context_pair_count = node_context[node][1]\n",
    "    context_set.add(context_node)\n",
    "    context_pair_count = context_pair_count + context_budget\n",
    "    node_context[node] = (context_set, context_pair_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateContextPairs(window, context_pairs, windowSize):    \n",
    "#     lastNode = window[-1]\n",
    "#     labelOfLastNode, budgetOfLastNode = lastNode\n",
    "    window_len = len(window)\n",
    "    middlenode_index = math.floor(window_len / 2)\n",
    "    middlenode, budgetofmiddlenode = window[middlenode_index]\n",
    "    for node in window:\n",
    "        context_node = node[0]\n",
    "        if context_node == middlenode:\n",
    "            continue\n",
    "#         context_pair1 = (context_node,middlenode)\n",
    "        context_pair = (middlenode, context_node)\n",
    "        \n",
    "        \n",
    "        updateSetCount(middlenode, context_node, budgetofmiddlenode)\n",
    "        \n",
    "#         set2 = node_context[middlenode][0]\n",
    "#         count2 = node_context[middlenode][1]\n",
    "#         updateSetCount(set2, context_node, count2, middlenode, budgetofmiddlenode)\n",
    "    \n",
    "        storeContextPairs(context_pair, budgetofmiddlenode, context_pairs)\n",
    "#         storeContextPairs(context_pair2, budgetofmiddlenode, context_pairs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNewNodeToWindow(window, vertex, budget):\n",
    "    window.append([vertex,budget])\n",
    "    return window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the toy graph\n",
    "G = createToyGraph()\n",
    "\n",
    "# Set the toy parameters \n",
    "WALK_LENGHT = 4\n",
    "BUDGET = 4\n",
    "WINDOW_SIZE = 1\n",
    "WINDOW_SIZE = WINDOW_SIZE*2+1\n",
    "WINDOW=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 20  loaded from  ../edgelists/karate-small.txt\n"
     ]
    }
   ],
   "source": [
    "# Parse the actual data\n",
    "G = parseEdgeList(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the actual parameters \n",
    "WALK_LENGHT = 3\n",
    "BUDGET = 1\n",
    "WINDOW_SIZE = 1\n",
    "\n",
    "WINDOW_SIZE = WINDOW_SIZE*2+1\n",
    "WINDOW=[]\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAdjList(graph):\n",
    "    adjdict = {}\n",
    "    for neighbor in graph:\n",
    "        neighbors = [n for n in G.neighbors(neighbor)]\n",
    "#         print(neighbors)\n",
    "        num_neihbors = len(neighbors)\n",
    "        adjdict[neighbor] = random.sample(neighbors, num_neihbors)\n",
    "#         degreedict[neighbor] = num_neihbors\n",
    "    return adjdict\n",
    "adjdict = getAdjList(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleFromExistingContext(node, budget):\n",
    "        context_nodes, num_walks = node_context[node]\n",
    "        num_nodes = len(context_nodes)\n",
    "        if num_nodes == 0:\n",
    "            return False\n",
    "        m = getPerNodeBudget(num_nodes, budget)\n",
    "        remainder = budget - (m * num_nodes)\n",
    "        for context_node in context_nodes:\n",
    "            context_pair1 = (context_node, node)\n",
    "            context_pair2 = (node, context_node)\n",
    "            count = 0\n",
    "            if context_pair1 in context_pairs:\n",
    "                count1 = context_pairs[context_pair1]\n",
    "            if count1 != 0 and num_walks > 0:\n",
    "                budget_for_this_node = math.floor((float(count1) / float(num_walks)) * budget)\n",
    "            else:\n",
    "                budget_for_this_node = m\n",
    "                if(remainder > 0):\n",
    "                    budget_for_this_node = budget_for_this_node + 1\n",
    "                    remainder = remainder - 1\n",
    "            budget = budget - budget_for_this_node\n",
    "            if budget_for_this_node > 0:\n",
    "                storeContextPairs(context_pair1, budget_for_this_node, context_pairs)\n",
    "                storeContextPairs(context_pair2, budget_for_this_node, context_pairs)\n",
    "            else:\n",
    "                break\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleFromExistingProbabilityDist(context_nodes, num_walks_passing, node, budget):\n",
    "    num_nodes = len(context_nodes)\n",
    "    if num_nodes == 0 or num_walks_passing == 0:\n",
    "        return False\n",
    "    m = getPerNodeBudget(num_nodes, budget)\n",
    "    remainder = budget - (m * num_nodes)\n",
    "    dist = {}\n",
    "    for context_node in context_nodes:\n",
    "        context_pair = (node, context_node)\n",
    "        context_pair_count = context_pairs[context_pair]\n",
    "        context_pair_prob = float(context_pair_count) / float(num_walks_passing)\n",
    "        dist[context_pair] = context_pair_prob\n",
    "    VA = VoseAlias(dist)\n",
    "    sampled_budgets = VA.sample_n(size=budget)\n",
    "    for sample_pair in sampled_budgets:\n",
    "        storeContextPairs(sample_pair, 1, context_pairs)\n",
    "        updateSetCount(sample_pair[0], sample_pair[1], 1)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFSRandomWalkWindow(graph, start, queue, context_pairs, window_size, walk_lenght, EPSILON):\n",
    "    while queue:\n",
    "        vertex, budget, current_walk_lenght, window = queue.pop(0)\n",
    "        randval = random.random()\n",
    "        #TODO change the probability inversely proportional to number of walks which passed through it\n",
    "        context_nodes, num_walks_passing = node_context[vertex]\n",
    "        if randval > EPSILON:\n",
    "#             print(\"sampling from existing\")\n",
    "            if sampleFromExistingProbabilityDist(context_nodes, num_walks_passing, vertex, budget) == True:\n",
    "                continue\n",
    "#         print(\"continuing\")\n",
    "        vertex_neighbors = adjdict[vertex]\n",
    "        num_neighbors = len(vertex_neighbors)\n",
    "        m = getPerNodeBudget(num_neighbors, budget)\n",
    "        remainder = budget - (m * num_neighbors)\n",
    "        current_walk_lenght += 1\n",
    "        for neighbor in vertex_neighbors:\n",
    "            budget_for_this_node = m \n",
    "            if(remainder > 0):\n",
    "                budget_for_this_node = budget_for_this_node + 1\n",
    "                remainder = remainder - 1\n",
    "#                 num_chosen_nodes = num_chosen_nodes + 1\n",
    "            if(budget_for_this_node > 0):\n",
    "                if len(window) == window_size:\n",
    "                    window.pop(0)\n",
    "                addNewNodeToWindow(window, neighbor, budget_for_this_node) \n",
    "                updateContextPairs(window, context_pairs, window_size)    \n",
    "                if current_walk_lenght < walk_lenght:\n",
    "                    queue.append((neighbor, budget_for_this_node, current_walk_lenght, list(window)))\n",
    "                window.pop(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running BFSRandomWalkWindow...\n"
     ]
    }
   ],
   "source": [
    "context_pairs = {}\n",
    "counter = 0\n",
    "print(\"Running BFSRandomWalkWindow...\")\n",
    "nodedegree = sorted(G.degree, key=lambda x: x[1], reverse=True)\n",
    "nodes = [n[0] for n in nodedegree]\n",
    "start = time.time()\n",
    "for startvertex in nodes:\n",
    "    WINDOW = [[startvertex, BUDGET]]\n",
    "    counter +=1\n",
    "    queue = [(startvertex, BUDGET, 0, WINDOW)]\n",
    "    BFSRandomWalkWindow(G, startvertex, queue, context_pairs, WINDOW_SIZE, WALK_LENGHT, 1)\n",
    "    if counter % 1000 == 0:\n",
    "        end = time.time()\n",
    "        t = end - start\n",
    "        start = time.time()\n",
    "        print(\"performance for \"+str(counter)+\" random walks : \",t)\n",
    "#         break\n",
    "# print(\"performance for 100 random walks : \",t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing context pairs to file...\n",
      "performance for 100 random walks :  0.018815994262695312\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing context pairs to file...\")    \n",
    "#Writing to file \n",
    "\n",
    "femb_iterative = open(embeddingsiterative, 'w')\n",
    "for (key, value) in context_pairs.items():\n",
    "    femb_iterative.write(str(key[0]) + \" \" + str(key[1]) + \" \" + str(value) + \"\\n\" )\n",
    "femb_iterative.close()\n",
    "end = time.time()\n",
    "t = end - start\n",
    "print(\"performance for 100 random walks : \",t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 4, 7, 5, 6, 3])"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([3, 4, 2, 7, 5, 6, 1])\n",
    "x[np.argpartition(x, (0,1,))]\n",
    "#Changes the given index(0) with the minimum element in the array "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
